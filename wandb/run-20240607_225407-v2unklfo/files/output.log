Freezing layer 'model.22.dfl.conv.weight'
[34m[1mAMP: [39m[22mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...
[34m[1mAMP: [39m[22mchecks skipped ‚ö†Ô∏è. Unable to load YOLOv8n due to possible Ultralytics package modifications. Setting 'amp=True'. If you experience zero-mAP or NaN losses you can disable AMP with amp=False.
[34m[1mtrain: [39m[22mScanning B:\GitHub\DualTraining.py\CivilianDataset\train\labels.cache... 1667 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1667/1667 [00:00<?, ?it/s]
[34m[1mval: [39m[22mScanning B:\GitHub\DualTraining.py\CivilianDataset\valid\labels.cache... 1666 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1666/1666 [00:00<?, ?it/s]
Plotting labels to YoloV8CivilianAircraft\AttemptGroupNorm4\labels.jpg...
  0%|          | 0/105 [00:00<?, ?it/s]
[34m[1moptimizer:[39m[22m 'optimizer=auto' found, ignoring 'lr0=0.0002' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically...
[34m[1moptimizer:[39m[22m AdamW(lr=0.00013, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)
Image sizes 640 train, 640 val
Using 8 dataloader workers
Logging results to [1mYoloV8CivilianAircraft\AttemptGroupNorm4
Starting training for 150 epochs...
